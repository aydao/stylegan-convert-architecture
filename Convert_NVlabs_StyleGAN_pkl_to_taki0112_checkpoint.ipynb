{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Convert NVlabs StyleGAN pkl to taki0112 checkpoint.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://raw.githubusercontent.com/aydao/stylegan-convert-architecture/master/Convert_NVlabs_StyleGAN_pkl_to_taki0112_checkpoint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJJVP1hkenNX",
        "colab_type": "text"
      },
      "source": [
        "# 0. Convert a NVlabs .pkl to a taki0112 checkpoint\n",
        "\n",
        "This notebook will let you use a simple script to copy over weights from a StyleGAN network in the idiosyncratic dnnlib architecture from Nvidia to a more general Tensorflow one courtesy of taki0112 on GitHub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfGxMBX_NdRL",
        "colab_type": "text"
      },
      "source": [
        "# 1. Use a GPU\n",
        "\n",
        "**Make sure that the notebook is running on a GPU**\n",
        "\n",
        "Edit -> Notebook Settings -> Hardware Accelerator -> GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_qy4XWNOQSe",
        "colab_type": "text"
      },
      "source": [
        "# 2. Get both StyleGAN repositories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPsxy0m1OcDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/NVlabs/stylegan.git\n",
        "!git clone https://github.com/taki0112/stylegan-tensorflow.git\n",
        "!git clone https://github.com/aydao/stylegan-convert-architecture.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMbDca0bO4hS",
        "colab_type": "text"
      },
      "source": [
        "Move the taki0112 and aydao code into the same directory as the NVlabs code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bmh7_paHO9Tv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv ./stylegan-tensorflow/* ./stylegan/\n",
        "!rm -rf ./stylegan-tensorflow/\n",
        "!mv ./stylegan-convert-architecture/* ./stylegan/\n",
        "!rm -rf ./stylegan-convert-architecture/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSlTXr1ad371",
        "colab_type": "text"
      },
      "source": [
        "# 3. Example conversion using the NVlabs FFHQ model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU0vHwZnPF09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd stylegan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jzaXYzyeSI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ./cache/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGkWqOkTd1Y9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_2PmAB4d1vp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mv ./karras2019stylegan-ffhq-1024x1024.pkl ./cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6NfGTc5d1xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python nvlabs_to_taki0112.py --nvlabs ./cache/karras2019stylegan-ffhq-1024x1024.pkl --dataset FFHQ --img_size 1024 --gpu_num 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zV73mr2uwzk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a temp dataset directory/file since the taki0112 expects it \n",
        "!mkdir ./dataset/FFHQ/\n",
        "!touch ./dataset/FFHQ/temp.png"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rcocpDUvKDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python main.py --dataset FFHQ --img_size 1024 --start_res 1024 --progressive False --phase draw --draw style_mix\n",
        "!python main.py --dataset FFHQ --img_size 1024 --start_res 1024 --progressive False --phase draw --draw truncation_trick"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqnWJgAMvlXg",
        "colab_type": "text"
      },
      "source": [
        "The images are in ./results/StyleGAN_FFHQ_1024to1024/paper_figure/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7_m5yMTxuFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib.pyplot import imshow\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh5fnmdEzrXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "style_mix = Image.open(\"./results/StyleGAN_FFHQ_1024to1024/paper_figure/figure03-style-mixing.jpg\", \"r\")\n",
        "imshow(np.asarray(style_mix))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3NW8eopztjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "truncation_trick = Image.open(\"./results/StyleGAN_FFHQ_1024to1024/paper_figure/figure08-truncation-trick.jpg\", \"r\")\n",
        "imshow(np.asarray(truncation_trick))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwLo4zV4NyGU",
        "colab_type": "text"
      },
      "source": [
        "# N. Upload your network-snapshot-######.pkl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqbnQh-A4ymj",
        "colab_type": "text"
      },
      "source": [
        "Either use the integrated browser (Files -> UPLOAD) to get your pkl uploaded or put it in Google drive and mount it to this instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHHrxJKPNPmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for me, mine is ./cache/network-snapshot-011185.pkl with a max resolution (lod0) of 512 pixels, and I'll just call the dataset \"mine\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txwcTOLW1V6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python nvlabs_to_taki0112.py --nvlabs ./cache/network-snapshot-011185.pkl --dataset mine --img_size 512 --gpu_num 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky7GLG9h8XhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a temp dataset directory/file since the taki0112 expects it \n",
        "!mkdir ./dataset/mine/\n",
        "!touch ./dataset/mine/temp.png\n",
        "!python main.py --dataset mine --img_size 512 --start_res 512 --progressive False --phase draw --draw style_mix\n",
        "!python main.py --dataset mine --img_size 512 --start_res 512 --progressive False --phase draw --draw truncation_trick"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzhThkT5-wKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib.pyplot import imshow\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7EvlQIp93gA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "style_mix = Image.open(\"./results/StyleGAN_mine_512to512/paper_figure/figure03-style-mixing.jpg\", \"r\")\n",
        "imshow(np.asarray(style_mix))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs4WGLCQ-zlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "truncation_trick = Image.open(\"./results//StyleGAN_mine_512to512/paper_figure/figure08-truncation-trick.jpg\", \"r\")\n",
        "imshow(np.asarray(truncation_trick))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXwtNXLZ-0PF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
